[{"authors":null,"categories":null,"content":"Emmanouil Karystinaios is a Ph.D. Student of artificial intelligence at the Computational Perception Institute of Johannes Kepler University. His research interests include Computational Musicology, Graph Neural Networks and Music Information Retrieval. Currently, he is working on Automatic Analysis of Symbolic Music using Graph Neural Networks (GNNs).\nHis past and current work includes, Cadence Detection, Structural Segmentation, and Similarity Metrics for Piano Performances.\n  Download my resumé.\n","date":1719446400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1719446400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Emmanouil Karystinaios is a Ph.D. Student of artificial intelligence at the Computational Perception Institute of Johannes Kepler University. His research interests include Computational Musicology, Graph Neural Networks and Music Information Retrieval.","tags":null,"title":"Emmanouil Karystinaios","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://emmanouil-karystinaios.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Emmanouil Karystinaios"],"categories":["Symbolic Representations","Graph Neural Networks","Music Information Retrieval","Cadence Detection","Interpretability"],"content":"From Notes to Insights: Visualizing Graph Neural Network Explanations with SMUG-Explain Graph Neural Networks (GNNs) are making waves in the world of Music Information Research (MIR). From predicting cadences to generating expressive performances, these networks are unlocking new potentials in understanding and processing musical scores. But there’s a catch — their complex, “black-box” nature makes them hard to interpret. That’s where SMUG-Explain comes in. This innovative framework is designed to generate and visualize explanations for GNNs applied to musical scores. Let’s dive into how SMUG-Explain works, its application in cadence detection, and its potential to bring AI and musicology closer together.\nThe Challenge: Understanding GNNs in Music GNNs are fantastic at capturing intricate relationships in graph-structured data, which is perfect for tasks like cadence detection and voice separation in music. However, they’re notoriously difficult to interpret. For musicians and researchers, this opacity can be a big problem. Imagine having a super-smart assistant who helps you analyze music but never explains why it made certain decisions. Frustrating, right?\nEnter SMUG-Explain, or Score MUsic Graph Explain. This is a framework for interpreting GNNs applied to music but it also integrates these explanations directly into the musical scores. By visualizing how each note and its features contribute to the model’s predictions, SMUG-Explain makes GNNs more transparent and understandable.\nHow Does SMUG-Explain Work? Graph-Based Representation of Musical Scores SMUG-Explain transforms a musical score into a graph where notes are vertices, and edges represent their temporal relationships. It uses four types of edges:\n Onset edges: Connect notes that start together. Consecutive edges: Link notes where one ends as the next begins. During edges: Connect notes that occur within the duration of another note. Rest edges: Connect notes across rests.     In this example, we view the score graph on an excerpt of a Perfect Authentic Cadence (PAC) with harmonic annotations written in Roman numerals.  Explanation Techniques SMUG-Explain employs several post-hoc, gradient-based explanation methods such as Saliency, Integrated Gradients, Deconvolution, and Guided Backpropagation. These techniques evaluate the importance of each note and its features in predicting specific musical events, such as cadences. Additionally, these methods allow us to derive attribution weights for every edge in the input graph. By selecting the top-k most important edges, we can construct an explanation subgraph that highlights the critical components influencing the model’s predictions.\nEvaluation of Explanations The quality of an explanation is assessed using fidelity metrics. For each explanation subgraph, the underlying cadence prediction model is run on the subgraph alone or on the input graph without the explanation subgraph. If the correct cadence label can be predicted using only the explanation subgraph, the explanation is deemed sufficient. Conversely, if the label changes when the input graph is used without the explanation subgraph, the explanation is considered necessary. An explanation that is both necessary and sufficient achieves a perfect fidelity score, indicating it provides a comprehensive and accurate insight into the model’s decision-making process.\nInteractive Visualization The framework features an interactive web interface built with the Verovio music engraving library. Users can click on individual notes to see the subgraphs that most contribute to the model’s predictions and the feature importance of each note. This interface not only makes the explanations accessible but also aligns them with traditional music notation, making it easier for musicians and researchers to understand.\nReal-World Applications: Mozart to Chopin Mozart’s Piano Sonata K280 In an excerpt from Mozart’s Piano Sonata K280, the underlying GNN analysis model accurately identified a perfect authentic cadence. Using the SMUG-Explain framework we can see that the explanations outline the descending melodic line and the bass arpeggiation leading to the cadence, aligning closely with traditional harmonic analysis. This example highlights the framework’s potential to support musicological research.\n   Potential reduction process of Smug-Explain. PAC indicates the predicted arrival point of the cadence.  When we isolate the explanation and apply a reduction process, retaining only the subgraph involved in the explanation, we are left with the essential structure of a textbook harmonic Perfect Authentic Cadence (PAC). This streamlined subgraph highlights the critical notes and relationships that define the PAC. While this process shows how SMUG-Explain can break down complex musical structures into their core elements, due to the complexity of musical reduction it isn’t a built-in feature just yet.\nChopin’s Nocturne in C Minor In Chopin’s Nocturne, SMUG-Explain …","date":1719446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719446400,"objectID":"1a56b53fc811de3277579778f9503ea5","permalink":"https://emmanouil-karystinaios.github.io/post/smug/","publishdate":"2024-06-27T00:00:00Z","relpermalink":"/post/smug/","section":"post","summary":"Discover SMUG-Explain, a framework that makes Graph Neural Networks in music interpretable. Explore its applications in cadence detection and musicology.","tags":["Academic"],"title":"From Notes to Insights - Visualizing Graph Neural Network Explanations with SMUG-Explain","type":"post"},{"authors":["Emmanouil Karystinaios","Francesco Foscarin","Gerhard Widmer"],"categories":null,"content":"","date":1714521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714521600,"objectID":"bf39d83009dd050485a18ac98dd595d0","permalink":"https://emmanouil-karystinaios.github.io/publication/2024_ijcai_musgconv/","publishdate":"2024-05-01T00:00:00Z","relpermalink":"/publication/2024_ijcai_musgconv/","section":"publication","summary":"In this paper we propose a new graph convolutional block, called MusGConv, specifically designed for the efficient processing of musical score data and motivated by general perceptual principles. We evaluate our approach on four different musical understanding problems, such as monophonic voice separation, harmonic analysis, cadence detection, and composer identification which, in abstract terms, translate to different graph learning problems, namely, node classification, link prediction, and graph classification. Our experiments demonstrate that MusGConv improves the performance on three of the aforementioned tasks while being conceptually very simple and efficient.","tags":[],"title":"Perception-Inspired Graph Convolution for Music Understanding Tasks","type":"publication"},{"authors":["Emmanouil Karystinaios","Francesco Foscarin","Gerhard Widmer"],"categories":null,"content":"","date":1714521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714521600,"objectID":"0d4f67cae5172baf1ef3abd414550086","permalink":"https://emmanouil-karystinaios.github.io/publication/2024_smc_smugexplain/","publishdate":"2024-05-01T00:00:00Z","relpermalink":"/publication/2024_smc_smugexplain/","section":"publication","summary":"In this work, we present Score MUsic Graph (SMUG)-Explain, a framework for generating and visualizing explanations of graph neural networks applied to arbitrary prediction tasks on musical scores. Our system allows the user to visualize the contribution of input notes (and note features) to the network output, directly in the context of the musical score. We provide an interactive interface based on the music notation engraving library Verovio. We showcase the usage of SMUG-Explain on the task of cadence detection in classical music.","tags":[],"title":"SMUG-Explain: A Framework for Symbolic Music Graph Explanations","type":"publication"},{"authors":["Emmanouil Karystinaios","Francesco Foscarin","Florent Jacquemard","Masahiko Sakai","Satoshi Tojo","Gerhard Widmer"],"categories":null,"content":"","date":1693353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693353600,"objectID":"d3814f7af9b07d81069cf3c67acb64b5","permalink":"https://emmanouil-karystinaios.github.io/publication/2023_cmmr_durationalgebra/","publishdate":"2023-11-04T00:00:00Z","relpermalink":"/publication/2023_cmmr_durationalgebra/","section":"publication","summary":"In this paper we present a formalization of musical durations and their operations in a semiring framework.","tags":[],"title":"8+8=4: Formalizing Time Units to Handle Symbolic Music Durations","type":"publication"},{"authors":["Emmanouil Karystinaios","Gerhard Widmer"],"categories":null,"content":"","date":1693353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693353600,"objectID":"680c53227abfe9874b5de9728a266f79","permalink":"https://emmanouil-karystinaios.github.io/publication/2023_ismir_chordgnn/","publishdate":"2023-11-04T00:00:00Z","relpermalink":"/publication/2023_ismir_chordgnn/","section":"publication","summary":"In this paper we present a graph model for Roman Numeral analysis in symbolic music.","tags":[],"title":"Roman Numeral Analysis with Graph Neural Networks: Onset-wise Predictions from Note-wise Features","type":"publication"},{"authors":["Huan Zhang","Emmanouil Karystinaios","Simon Dixon","Gerhard Widmer","Carlos Canchino Chacon"],"categories":null,"content":"","date":1693353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693353600,"objectID":"33ea8325a7096908c8121f1b18d371d2","permalink":"https://emmanouil-karystinaios.github.io/publication/2023_ismir_symrep/","publishdate":"2023-11-04T00:00:00Z","relpermalink":"/publication/2023_ismir_symrep/","section":"publication","summary":"In this paper, we present a series of systematic experiments to investigate the impact of symbolic representations for three piece-level tasks.","tags":[],"title":"Symbolic Music Representations for Classification Tasks: A Systematic Evaluation","type":"publication"},{"authors":["Silvan Peter","Carlos Cancino-Chacón","Francesco Foscarin","Andrew Philip McLeod","Florian Henkel","Emmanouil Karystinaios","Gerhard Widmer"],"categories":null,"content":"","date":1687737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687737600,"objectID":"b1842d65d5bb6fab5ad2b985660e05e4","permalink":"https://emmanouil-karystinaios.github.io/publication/2023_tismir_asap/","publishdate":"2023-06-26T00:00:00Z","relpermalink":"/publication/2023_tismir_asap/","section":"publication","summary":"This paper introduces the (n)-ASAP dataset, a dataset with note level alignment annotations.","tags":[],"title":"Automatic Note-Level Score-to-Performance Alignments in the ASAP Dataset","type":"publication"},{"authors":["Emmanouil Karystinaios","Francesco Foscarin","Gerhard Widmer"],"categories":null,"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"6ea129a13f7288ba486fbad65a16f768","permalink":"https://emmanouil-karystinaios.github.io/publication/2023_ijcai_vocsep/","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/publication/2023_ijcai_vocsep/","section":"publication","summary":"In this paper we present a Heterogeneous Graph model of the musical score for Voice Separation in Symbolic Music.","tags":[],"title":"Musical Voice Separation as Link Prediction: Modeling a Musical Perception Task as a Multi-Trajectory Tracking Problem","type":"publication"},{"authors":["Carlos Cancino-Chacón","Silvan Peter","Patricia Hu","Emmanouil Karystinaios","Florian Henkel","Francesco Foscarin","Nimrod Varga","Gerhard Widmer"],"categories":null,"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"ce65f755cd4f9393ef873df547397c18","permalink":"https://emmanouil-karystinaios.github.io/publication/2023_ijcai_accompanion/","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/publication/2023_ijcai_accompanion/","section":"publication","summary":"This paper introduces the ACCompanion, an expressive accompaniment system.","tags":[],"title":"The ACCompanion: Combining Reactivity, Robustness, and Musical Expressivity in an Automatic Piano Accompanist","type":"publication"},{"authors":["Emmanouil Karystinaios","Gerhard Widmer"],"categories":null,"content":"","date":1661817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661817600,"objectID":"dff6f8a3e34be5b041aa35f93523348b","permalink":"https://emmanouil-karystinaios.github.io/publication/2022_ismir_cadet/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/publication/2022_ismir_cadet/","section":"publication","summary":"In this paper we present a Graph model of musical score and a Graph Neural Network to detect cadences.","tags":[],"title":"Cadence Detection in Symbolic Classical Music using Graph Neural Networks","type":"publication"},{"authors":["Carlos Canchino Chacon","Silvan Peter","Emmanouil Karystinaios","Francesco Foscarin","Maarten Grachten","Gerhard Widmer"],"categories":null,"content":"","date":1653868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653868800,"objectID":"ce7d4993b6038b59908a9dba59102a68","permalink":"https://emmanouil-karystinaios.github.io/publication/2022_mec_partitura/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/publication/2022_mec_partitura/","section":"publication","summary":"In this paper we present partitura, a Python package music symbolic music processing.","tags":[],"title":"partitura: A Python Package for Handling Symbolic Musical Data","type":"publication"},{"authors":["Francesco Foscarin","Emmanouil Karystinaios","Silvan Peter","Carlos Canchino Chacon","Maarten Grachten","Gerhard Widmer"],"categories":null,"content":"","date":1653868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653868800,"objectID":"d160cc8c263200f6c3d8d35185729428","permalink":"https://emmanouil-karystinaios.github.io/publication/2022_mec_match/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/publication/2022_mec_match/","section":"publication","summary":"In this paper we present the match file format, a format for encoding alignments between performances and scores.","tags":[],"title":"The match file format: Encoding Alignments between Scores and Performances","type":"publication"},{"authors":["Carlos Canchino Chacon","Silvan Peter","Emmanouil Karystinaios","Gerhard Widmer"],"categories":null,"content":"","date":1648598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648598400,"objectID":"9b04d291ad1e8164872d64f51bb15214","permalink":"https://emmanouil-karystinaios.github.io/publication/2021_rppw_expressive/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/publication/2021_rppw_expressive/","section":"publication","summary":"In this work, we present some preliminary results about quantifying differences in expressive piano performances in the context of computational generative models.","tags":[],"title":"Towards Quantifying Differences in Expressive Piano Performances: Are Euclidean-like Distance Measures Enough?","type":"publication"},{"authors":["Emmanouil Karystinaios"],"categories":[],"content":"On Performance Similarity and Structure Segmentation Emmanouil Karystinaios | article\n Introduction Our objective is to find a way to quantify similarity of performances for which we have a matched score. But first, we have to answer the following questions :\n What is performance similarity How to measure siilarity in match scores? Which similarity metric to use ? Why measure performance similarity? What elements affect our perception of performance similarity?   Self-Similarity Matrices The concept of self-similarity matrices is fundamental for capturing structural properties of music recordings. Generally, one starts with a feature space L containing the elements of the feature sequence under consideration as well as with a similarity measure $f : \\mathcal{L} \\times \\mathcal{L} \\to \\mathbb{R}$.\n Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Interval Vectors  Definition An interval vector is an array of natural numbers which summarize the intervals present in a set of pitch classes. There is an equivalence between complementary intervals within the octave for example $2^{nd}$ minor and $7^{nth}$ major intervals, etc.  Examples :\n Any Major chord : $ [0, 0, 1, 1, 1, 0 ] $ Any Minor chord : $ [0, 0, 1, 1, 1, 0 ] $   Interval Vectors and Cadences    Typical Cadences      $\\textrm{V}$ \u0026amp; - \u0026amp; $\\textrm{I}$ authentic   $\\textrm{I}$ \u0026amp; - \u0026amp; $\\textrm{V}$ half   $\\textrm{IV}$ \u0026amp; - \u0026amp; $\\textrm{I}$ plagal   $\\textrm{V}$ \u0026amp; - \u0026amp; $\\textrm{VI}$ deceptive    Interval Vectors are commutative, i.e. $\\textrm{V} \\to \\textrm{I} = \\textrm{I} \\to \\textrm{V} $:\n $ (\\textrm{V/I})_{maj} = [1, 2, 2, 2, 3, 0] $ $ (\\textrm{V/I})_{min} = [2, 1, 2, 3, 2, 0] $   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  For every window $w_i^j$ we compute the interval vector of all notes in thye window/ Therefore, $\\textrm{Int_Vec}(w_i^j)\\in \\mathbb{N}^6$. $$ \\mathcal(W) = \\sum_{i=1}^N\\sum_{j=1}^\\nu \\textrm{Int_Vec}(w_i^j) $$ Then, let $\\mathcal{X}$ be some matrix decomposition of $\\mathcal{W}$. The SSM $\\mathcal{S}$ of $\\mathcal{X}$ is: $$ \\mathcal{S} = \\frac{\\mathcal{X} \\cdot \\mathcal{X}}{| \\mathcal{X} |^2} $$\n Test \\begin{tikzpicture} \\matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em] { F \u0026amp; B \\ \u0026amp; A \\}; \\path[-stealth] (m-1-1) edge node [above] {$\\beta$} (m-1-2) (m-1-2) edge node [right] {$\\rho$} (m-2-2) (m-1-1) edge node [left] {$\\alpha$} (m-2-2); \\end{tikzpicture}\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne  Two  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1612483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612483200,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://emmanouil-karystinaios.github.io/slides/example/","publishdate":"2021-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"On Performance Similarity and Structure Segmentation.","tags":"Department of Computational Perception","title":"Slides","type":"slides"},{"authors":["Emmanouil Karystinaios"],"categories":["Symbolic Representations"],"content":"Harmonic Trajectories in the Tonnetz Introduction The Neo-Riemannian Tonnetz is a way of visualizing musical relationships between chords. It was developed by music theorists to help understand how chords can transition smoothly from one to another.\nImagine a grid or network of interconnected points. Each point represents a different chord. The horizontal lines connect chords that are closely related, while the vertical lines connect chords that share similar tonal qualities.\nThe Tonnetz is based on the idea that chords can be transformed or changed into one another through small movements. These transformations are represented by diagonal lines on the Tonnetz. For example, a chord can be transformed into another chord by changing one note at a time, moving in a specific direction on the grid.\nBy studying the Tonnetz, musicians and theorists can analyze chord progressions and see how different chords are related to each other. It provides a visual representation of the harmonic possibilities and helps to explain the underlying structure of music.\nIn simple terms, the Neo-Riemannian Tonnetz is a grid that shows how chords in music are connected and can be transformed smoothly from one to another. It helps musicians and theorists understand how chords fit together and how they can create pleasing transitions in music.\nOverview PLR operations, also known as Parallel, Leading Tone, and Relative operations, are a set of chord transformations used in music theory. These operations help musicians understand how chords can be changed while maintaining a similar musical function.\n  Parallel operation: This operation involves changing a chord to another chord with the same root note but a different quality. For example, if you have a major chord, you can transform it into a minor chord by lowering the third note. This maintains the same root note but gives a different emotional quality to the chord.\n  Leading Tone operation: The leading tone refers to the seventh note of a major scale, which is one step below the tonic note. In this operation, a chord is transformed by changing the root note to its leading tone. This creates a sense of tension and a desire to resolve back to the tonic chord. For example, if you have a C major chord, you can transform it into a B diminished chord by changing the root note to B.\n  Relative operation: This operation involves changing a chord to another chord that shares a similar tonal quality but has a different root note. For example, if you have a C major chord, you can transform it into an A minor chord by changing the root note to A. The relative operation allows for smooth transitions between chords that have a related sound.\n  These PLR operations provide musicians with tools to transform chords while maintaining certain musical characteristics. By understanding these operations, musicians can create interesting chord progressions, establish tension and resolution, and explore different harmonic possibilities in their music.\nThe PLR operations are the foundation of the Tonnetz.\nThese operations/ transformations are the principal transformations of the Neo-Riemmanian theory which was mainly conceived by David Lewin (1933–2003). The mirror process is relative to the chord intervalic relations not the position of the shape in the circle.\nPLR as Group Operations The PLR group acts simply transitively on the set {$ n_M,n=0…11$} $\\cup$ { $n_m,n=0…11 $} of the 24 major and minor triads, where $n_M$ (resp. $n_m$) represents a major (resp. minor) triad with root n in the usual semi-tone encoding of pitch classes.\nIt is isomorphic to the dihedral group D24 of order 24, and is generated by the following two transformations.\nThe transformation $L: \\mathbb{Z} _{24} \\to \\mathbb{Z} _{24}$ is called the leading-tone operation, and is such that:\n$$ L(n_M)=(n+4)_m \\textrm{ and the complementary } L(n_m)=(n+8)_M $$\nThe transformation $R: \\mathbb{Z} _{24} \\to \\mathbb{Z} _{24}$ is called the relative operation, and is such that:\n$$ R(n_M)=(n+9)_m \\textrm{ and similarly the complementary } $$\nThough not a generator, the operation $P=(RL)3R$, called the parallel operation, is often considered, and is such that $P(n_M)=n_m$\nTrajectories in the Tonnetz The trajectory is defined as a path $\\mathcal{X} $ in the Tonnetz $T$, i.e. an ordered list of positions in the space $T$.\nLet us investigate some basic scenarios for trajectory construction. Placing the first note in the Tonnetz has no bearing on the descriptors we ultimately compute, so we can simply pick an arbitrary position. Now we consider the case where we have to place two notes: one of them is placed as in the previous case, and the second one is placed according to a criterion depending on a distance measure. To this end, we define a function $dist: \\mathbb{Z} _{12} \\times \\mathbb{Z} _{12} \\to \\mathbb{N}$, which assigns to the pitch class representation of notes, $x$ and $y$, their distance according to a given Tonnetz as: \\begin{equation} …","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"23fe897eea83541d26eed6aa3f3d54e1","permalink":"https://emmanouil-karystinaios.github.io/post/tonnetz/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/tonnetz/","section":"post","summary":"Introducing the Tonnetz and related applications for composition and musical analysis.","tags":["Academic"],"title":"Harmonic Trajectories in the Tonnetz","type":"post"},{"authors":["Emmanouil Karystinaios","Corentin Guichaoua","Moreno Andreatta","Louis Bigo","Isabelle Bloch"],"categories":null,"content":"","date":1606694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606694400,"objectID":"54140727d157e7f951d46ca0ca8143d2","permalink":"https://emmanouil-karystinaios.github.io/publication/2020_jim_tonnetz/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/publication/2020_jim_tonnetz/","section":"publication","summary":"In this article, we propose a new approach for stylistic music classification, driven by chord material. we present a novel approach without vocabulary restrictions on the chord material but rather an evaluation of the total harmonic content following closely Louis Bigo's apporach on trajectories in generic simplicial complexes.","tags":[],"title":"Music genre descriptor for classification based on Tonnetz trajectories","type":"publication"}]